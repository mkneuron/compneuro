function [  ] = actor_critic_assignment(  )
% Main function
%% TODOS
%{
Environment TODO:
--------
Make sure that all values make sense.
e.g. map_radius

Actor-Critic loop TODO:
--------
* implement learning rate
* Every set of 4 trials must contain a different location. STILL NEEDS WORK
* Close actor-critic loop

Plotting TODO:
--------
* Basically everything

%}
%% init vars

act_Cells = 8;        % equivalent to the number of possible actions
P_Cels = 493;      % number of place cells
pool_radius = 133;      % radius in cm (aka pixels ?)
platform_R = 6;         % platform radius in cm (aka pixels ?)
p_std = 16;             % place cell std, aka sigma
strict_place = 1;       % forbid place cell centers outside maze
totalTrials = 22;       % number of total trials
plat_posit = 1:4;       % number of platform positions
timeline = 1:0.1:120;   % time as described in paper
random_start = 0;       % toggle random start (see voluntary_jump.m) 

%% Get environment map and coordinates of place cells
% e.g. [map, cell_coord, platform_mask] = ...
%       RL_env(Pcel, pool_radius, platform_R, p_std, strict_place)
[map, cell_coord, platform] = RL_env(P_Cels,pool_radius, ...
                                     platform_R,p_std,strict_place); 
map_dims=size(map,2); % map dimensions

%% Initialize start and end points
% Define rat starting position.



%% Actor-Critic loop
%{
TODO:

* Every set of 4 trials must contain a different location.
* Make trials end after 120 seconds
      need to fix time first
* Up to 22 trials
* Close actor-critic loop

%}

% Initialize weights.
% actor weights as named in the paper
z_ij = rand(P_Cels, act_Cells); % weights place cell to actor
w_critic      = zeros(P_Cels,1);  % weights of critic

% init loop variables
daily_trial = 0;
pred_err    = 0;
for trialN0=1:totalTrials

    % reset each day
    if mod(trialN0-1,5) == 0 % every fourth trial 
        rat_position_v = voluntary_jump(map_dims,pool_radius);
        daily_trial = 0; % reset platform iterator
    end
    
    % iterators
    daily_trial = daily_trial +1; % iterates through the platform positions
    
    % reset each trial
    Cprev = 0;
    rat_position = rat_position_v(daily_trial,:);
    
    for t=1:length(timeline) % single trial loop
        
        % get spike rates for place cells
        
        spikeCounts = placeCells_spikeRate(rat_position,cell_coord,p_std);
        
        %% Actor choose an allowed action.
        
        % this needs to go away because the boundaries now are bouncy
%         is_legal = 0; %
%         while ~is_legal
%             
%             % Move the bloody rat.
%             [updated_position] = move_rat (rat_position, direction);
%             if map(updated_position(1,1), updated_position(1,2)) == 1
%                 is_legal = 1;
%             else
%                 warning('Dumb rat wants to exit the swimming pool');
%                 % dumb rat don't know no better
%             end
%         end
        
        % Momentum: 25% time, the actor decides on change of movement. The
        % other 75% the mouse keeps going in a direction.
        
        [direction, z_ij_dx] = actor(act_Cells, pred_err, spikeCounts, z_ij);
        if rand > 0.75
            updated_position = direction;
            momentum = updated_position-rat_position;
        else
            momentum = position-old_position;
            updated_position = rat_position + momentum;
        end
        
        % check if the mouse hit the boundary. If it did, bounce it off.
        if map(updated_position(1,1), updated_position(1,2)) == 0
            updated_position = updated_position -2*momentum;
        end
        
        % update positions
        old_position     = rat_position; % needed to calculate momentum
        rat_position     = updated_position;
        
        %% Critic Output:
        % C : The critic's take of the value function
        % dt: Prediction Error
        % dw: change in weights
        %% Critic Input:
        % spikeCounts: accessible with placeCells_spikeRate()
        % w_critic   : the weights of the critic
        % Reward     : reward
        % Cprev      : The C that is output by the critic in t-1, see below
        % The value function is calculated with C_t+1, but since we can't
        % predict the future we make everyhting go a step back in time.
        
        % [C-value fuction, prediction error, change in weights]
        [C,pred_err,dw]= Critic(spikeCounts,w_critic,Reward,Cprev);
        Cprev=C;
        
        % Update Weights
        z_ij = z_ij + z_ij_dx; % actor
        w_critic= w_critic + eta_c*dw;  % critic
    end
end
end
